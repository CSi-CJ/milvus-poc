#!/usr/bin/env python3
"""
æµ‹è¯•ChatGPTå¸§ç­–ç•¥é›†æˆåˆ°å®Œæ•´ç³»ç»Ÿ
"""

import asyncio
import logging
from multimodal_indexer.config import load_config
from multimodal_indexer.index_manager import IndexManager
from multimodal_indexer.parsers.factory import create_default_registry
from multimodal_indexer.embedder import VectorEmbedder
from multimodal_indexer.file_processor import FileProcessor

async def test_chatgpt_frame_strategy_integration():
    """æµ‹è¯•ChatGPTå¸§ç­–ç•¥é›†æˆ"""
    
    # è®¾ç½®è¯¦ç»†æ—¥å¿—
    logging.basicConfig(
        level=logging.INFO,
        format='%(asctime)s - %(name)s - %(levelname)s - %(message)s'
    )
    
    print("ğŸ§ª æµ‹è¯•ChatGPTå¸§ç­–ç•¥é›†æˆåˆ°å®Œæ•´ç³»ç»Ÿ")
    print("="*60)
    
    # åŠ è½½é…ç½®
    config = load_config()
    
    # åˆ›å»ºç»„ä»¶
    parser_registry = create_default_registry(config.processing.__dict__)
    embedder = VectorEmbedder(config.embedding)
    index_manager = IndexManager(config.milvus)
    
    try:
        # æ¸…ç†ç°æœ‰æ•°æ®
        print("ğŸ—‘ï¸  æ¸…ç†ç°æœ‰æ•°æ®...")
        try:
            # åˆ é™¤æ‰€æœ‰å¯èƒ½çš„é›†åˆ
            for collection_name in ["multimodal_content", "multimodal_files"]:
                try:
                    index_manager.drop_collection(collection_name)
                    print(f"âœ… åˆ é™¤é›†åˆ: {collection_name}")
                except Exception as e:
                    print(f"âš ï¸  é›†åˆ {collection_name} ä¸å­˜åœ¨æˆ–åˆ é™¤å¤±è´¥: {e}")
        except Exception as e:
            print(f"âš ï¸  æ¸…ç†æ•°æ®æ—¶å‡ºç°é”™è¯¯: {e}")
        
        # åˆ›å»ºå¤„ç†å™¨
        processor = FileProcessor(parser_registry, embedder, index_manager, config)
        
        # åªå¤„ç†è§†é¢‘æ–‡ä»¶
        video_file = "./files/ä¸ªæ€§åŒ–æ¨è.mp4"
        
        print(f"ğŸ”„ å¼€å§‹å¤„ç†è§†é¢‘æ–‡ä»¶: {video_file}")
        print("   ä½¿ç”¨ChatGPTå¸§ç­–ç•¥: 1 FPS + ç›¸ä¼¼åº¦è¿‡æ»¤ + é‡ç‚¹å¸§è¯†åˆ«")
        
        result = await processor.process_file(video_file)
        
        if result['status'] == 'success':
            print(f"âœ… è§†é¢‘å¤„ç†æˆåŠŸ!")
            print(f"   - åµŒå…¥å‘é‡æ•°é‡: {result['embeddings_count']}")
            print(f"   - å¤„ç†æ—¶é—´: {result['processing_time']:.2f}s")
            
            # æœç´¢æµ‹è¯• - å¤šä¸ªæŸ¥è¯¢
            test_queries = [
                "è´¢åŠ¡æŠ¥å‘Š",
                "XR",
                "MindSearch",
                "æ—©ä¸Šå¥½",
                "è®¡åˆ’"
            ]
            
            print(f"\nğŸ” æœç´¢æµ‹è¯• ({len(test_queries)} ä¸ªæŸ¥è¯¢)...")
            print("="*60)
            
            for query in test_queries:
                print(f"\nğŸ” æŸ¥è¯¢: '{query}'")
                query_vector = embedder.embed_text(query)
                search_results = index_manager.search_vectors(
                    query_vectors=[query_vector.tolist()],
                    top_k=3
                )
                
                print(f"   æ‰¾åˆ° {len(search_results)} ä¸ªç»“æœ:")
                for i, result in enumerate(search_results, 1):
                    content_type = result.get('content_type', 'unknown')
                    file_name = result.get('file_name', 'unknown')
                    score = result.get('score', 0)
                    
                    print(f"   {i}. ç±»å‹: {content_type}, æ–‡ä»¶: {file_name}, è¯„åˆ†: {score:.4f}")
                    
                    # æ˜¾ç¤ºOCRæ–‡æœ¬
                    ocr_text = result.get('ocr_text', '')
                    if ocr_text:
                        # æˆªå–å‰100ä¸ªå­—ç¬¦æ˜¾ç¤º
                        display_text = ocr_text[:100] + "..." if len(ocr_text) > 100 else ocr_text
                        print(f"      ğŸ“ OCRæ–‡æœ¬: {display_text}")
                    
                    # æ˜¾ç¤ºå¸§ç­–ç•¥ä¿¡æ¯
                    if 'frame_strategy' in result:
                        strategy_info = result['frame_strategy']
                        print(f"      ğŸ¯ å¸§ç­–ç•¥: ç›¸ä¼¼åº¦è¿‡æ»¤={strategy_info.get('similarity_filtering', False)}, "
                              f"ä¼˜å…ˆçº§æ’åº={strategy_info.get('priority_ranking', False)}")
            
            # æ˜¾ç¤ºè¯¦ç»†çš„OCRæå–ç»Ÿè®¡
            print(f"\nğŸ“Š OCRæå–ç»Ÿè®¡:")
            print("="*60)
            
            # è·å–æ‰€æœ‰ç»“æœæŸ¥çœ‹OCRæå–æƒ…å†µ
            all_results = index_manager.search_vectors(
                query_vectors=[embedder.embed_text("").tolist()],
                top_k=50
            )
            
            total_items = len(all_results)
            items_with_ocr = sum(1 for r in all_results if r.get('ocr_text', '').strip())
            total_ocr_length = sum(len(r.get('ocr_text', '')) for r in all_results)
            
            print(f"   æ€»é¡¹ç›®æ•°: {total_items}")
            print(f"   åŒ…å«OCRæ–‡æœ¬çš„é¡¹ç›®: {items_with_ocr}")
            print(f"   OCRè¦†ç›–ç‡: {items_with_ocr/total_items*100 if total_items > 0 else 0:.1f}%")
            print(f"   æ€»OCRæ–‡æœ¬é•¿åº¦: {total_ocr_length} å­—ç¬¦")
            print(f"   å¹³å‡æ¯é¡¹OCRé•¿åº¦: {total_ocr_length/items_with_ocr if items_with_ocr > 0 else 0:.1f} å­—ç¬¦")
            
            # æ˜¾ç¤ºå¸§ç­–ç•¥æ•ˆæœ
            frame_strategy_items = [r for r in all_results if 'frame_strategy' in r]
            if frame_strategy_items:
                print(f"   ä½¿ç”¨å¸§ç­–ç•¥çš„é¡¹ç›®: {len(frame_strategy_items)}")
                print("   å¸§ç­–ç•¥ç‰¹æ€§:")
                for item in frame_strategy_items[:3]:  # æ˜¾ç¤ºå‰3ä¸ª
                    strategy = item.get('frame_strategy', {})
                    ocr_info = item.get('ocr_extraction', {})
                    print(f"     - æˆåŠŸå¸§æ•°: {ocr_info.get('successful_frames', 0)}/{ocr_info.get('total_frames', 0)}")
                    print(f"       å¹³å‡ç½®ä¿¡åº¦: {ocr_info.get('average_confidence', 0):.3f}")
                    print(f"       ç›¸ä¼¼åº¦è¿‡æ»¤: {strategy.get('similarity_filtering', False)}")
                    print(f"       ä¼˜å…ˆçº§æ’åº: {strategy.get('priority_ranking', False)}")
        else:
            print(f"âŒ è§†é¢‘å¤„ç†å¤±è´¥: {result.get('error', 'unknown error')}")
            # æ˜¾ç¤ºè¯¦ç»†é”™è¯¯ä¿¡æ¯
            if 'traceback' in result:
                print(f"è¯¦ç»†é”™è¯¯: {result['traceback']}")
    
    finally:
        index_manager.close()

if __name__ == "__main__":
    asyncio.run(test_chatgpt_frame_strategy_integration())